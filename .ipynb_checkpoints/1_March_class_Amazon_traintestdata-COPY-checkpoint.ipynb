{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and specifications\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#To validate/cross validate--create training and test data\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call data\n",
    "amazon = pd.read_csv('Amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create 4 object for labels and features of TRAIN and TEST\n",
    "\n",
    "raw_data_train, raw_data_test, y_train, y_test = train_test_split(amazon, amazon['helpful'],\n",
    "                                                                 test_size=0.2, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 13)\n",
      "(91000, 13)\n",
      "(364000,)\n",
      "(91000,)\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_train.shape)\n",
    "print(raw_data_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_train.to_csv('raw_data_train.csv')\n",
    "raw_data_test.to_csv('raw_data_test.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "y_test.to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6 notebook Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryClassificationPerformance():\n",
    "    '''Performance measures to evaluate the fit of a binary classification model'''\n",
    "    \n",
    "    def __init__(self, predictions, labels, desc, probabilities=None):\n",
    "        '''Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y'''\n",
    "        '''probabilities-optional, probability that Y is equal to True'''\n",
    "        self.probabilities = probabilities\n",
    "        self.performance_df = pd.concat([pd.DataFrame(predictions), pd.DataFrame(labels)], axis=1)\n",
    "        self.performance_df.columns = ['preds', 'labls']\n",
    "        self.desc = desc\n",
    "        self.performance_measures = {}\n",
    "  \n",
    "    def compute_measures(self):\n",
    "        '''Compute performance measures defined by Flach p. 57'''\n",
    "        self.performance_measures['Pos'] = self.performance_df['preds'].sum()\n",
    "        self.performance_measures['Neg'] = self.performance_df.shape[0] - self.performance_df['preds'].sum()\n",
    "        self.performance_measures['TP'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == True)).sum()\n",
    "        self.performance_measures['TN'] = ((self.performance_df['preds'] == False) & (self.performance_df['labls'] == False)).sum()\n",
    "        self.performance_measures['FP'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == False)).sum()\n",
    "        self.performance_measures['FN'] = ((self.performance_df['preds'] == False) & (self.performance_df['labls'] == True)).sum()\n",
    "        self.performance_measures['Accuracy'] = (self.performance_measures['TP'] + self.performance_measures['TN']) / (self.performance_measures['Pos'] + self.performance_measures['Neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91000, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('raw_data_test.csv')\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      400196        411245  411246  B0040WCR6O  A3FFKU2MTCOBM1   \n",
      "1       38020        110761  110762  B003XUJ3RK   AC2SMT7WEOBQM   \n",
      "2      366458        192489  192490  B006GA666U  A39FOS1KTT1T8Z   \n",
      "3       43625        544264  544265  B00125PX8Q  A1XZXAV5OXD08P   \n",
      "4      211610        494698  494699  B000BZZKVS  A15P774MWM8W4R   \n",
      "\n",
      "             ProfileName  HelpfulnessNumerator  HelpfulnessDenominator  Score  \\\n",
      "0  new yorker \"drealyea\"                     0                       0      1   \n",
      "1                   Bill                     0                       0      5   \n",
      "2                 kendon                     0                       0      2   \n",
      "3               Good 4 U                     0                       0      5   \n",
      "4             D. Dutcher                     8                      11      2   \n",
      "\n",
      "         Time                            Summary  \\\n",
      "0  1340323200           Overpriced, disapointing   \n",
      "1  1325289600                     Quick and easy   \n",
      "2  1297641600       Not as smooth as I hoped....   \n",
      "3  1325116800               Great & organic buzz   \n",
      "4  1144627200  Great for a long run or bike ride   \n",
      "\n",
      "                                                Text  helpScore helpful  \n",
      "0  Although the actual contents are worthy of bei...        NaN   False  \n",
      "1  For the record, I am (cut and paste) the same ...        NaN   False  \n",
      "2  This coffee is strong and bold, but very harsh...        NaN   False  \n",
      "3  Steaz energy drinks are great tasting & great ...        NaN   False  \n",
      "4  I started running a couple years ago, and I ra...   0.727273   False  \n",
      "0.0726923076923\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91000, 131072)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "#from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "\n",
    "#Get the instance\n",
    "hv = joblib.load('hv.pkl')\n",
    "X_hv = hv.fit_transform(amazon.Text)\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#transformer = TfidfTransformer()\n",
    "\n",
    "#Get the transformer\n",
    "transformer = joblib.load('transformer.pkl')\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  reviewLen\n",
      "0      5        519\n",
      "1      5       1395\n",
      "2      5        821\n",
      "3      5         82\n",
      "4      5        169\n",
      "5      5        159\n",
      "6      4        297\n",
      "7      2        628\n",
      "8      1        607\n",
      "9      3       3188\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\"]]\n",
    "print(X_quant_features.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try person who wrote it\n",
    "### try sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 131074)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `X`, scaled matrix of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 131074)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sc.pkl', 'sc.pkl_01.npy', 'sc.pkl_02.npy', 'sc.pkl_03.npy']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_matrix)\n",
    "print(X.shape)\n",
    "\n",
    "joblib.dump(sc, 'sc.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Neg': 337477, 'TP': 12194, 'FN': 14426, 'TN': 323051, 'FP': 14329, 'Pos': 26523, 'Accuracy': 0.92100274725274722}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X, y)\n",
    "joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "svm_performance.compute_measures()\n",
    "print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Neg': 338281, 'TP': 13336, 'FN': 13284, 'TN': 324997, 'FP': 12383, 'Pos': 25719, 'Accuracy': 0.92948626373626375}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "lgs.fit(X, y)\n",
    "joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "\n",
    "lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "lgs_performance.compute_measures()\n",
    "print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Neg': 305222, 'TP': 17117, 'FN': 9503, 'TN': 295719, 'FP': 41661, 'Pos': 58778, 'Accuracy': 0.85943956043956049}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X, y)\n",
    "joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "\n",
    "nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "nbs_performance.compute_measures()\n",
    "print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
