{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and specifications\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('Amazon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data, type, dimensions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon is <class 'pandas.core.frame.DataFrame'>\n",
      "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
      "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
      "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
      "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
      "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
      "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       2      2  1294185600   \n",
      "1                     0                       0      5  1349740800   \n",
      "2                     0                       0      5  1329264000   \n",
      "3                     1                       1      4  1248307200   \n",
      "4                     0                       0      5  1333238400   \n",
      "\n",
      "                     Summary  \\\n",
      "0           Not as pictured.   \n",
      "1                      seeds   \n",
      "2              I'm addicted!   \n",
      "3  I wanted to love these...   \n",
      "4    Excellent chamomile tea   \n",
      "\n",
      "                                                Text  helpScore helpful  \n",
      "0  I was looking forward to try cranberry apple f...        0.5   False  \n",
      "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
      "2  I've finally found the best cereal in the worl...        NaN   False  \n",
      "3  I originally bought these chips because I'd he...        1.0   False  \n",
      "4  Really excellent tea, flowers are visible in t...        NaN   False  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(455000, 13)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('amazon is', type(amazon) ) \n",
    "print(amazon.head(5))\n",
    "amazon.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1000, 13)\n"
     ]
    }
   ],
   "source": [
    "# create a subset of \"amazon\" that contains all the columns but only only the first 1000 rows\n",
    "amazon_subset = amazon[:1000]\n",
    "print(type(amazon_subset))\n",
    "print(amazon_subset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Id',\n",
       " 'ProductId',\n",
       " 'UserId',\n",
       " 'ProfileName',\n",
       " 'HelpfulnessNumerator',\n",
       " 'HelpfulnessDenominator',\n",
       " 'Score',\n",
       " 'Time',\n",
       " 'Summary',\n",
       " 'Text',\n",
       " 'helpScore',\n",
       " 'helpful']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(amazon_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "9    False\n",
       "Name: helpful, dtype: bool"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label = amazon_subset[\"helpful\"]\n",
    "Label.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This creates an ndarray and can be seen using \".values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label.shape\n",
    "type(Label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the features (or selecting them from amazon_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = amazon_subset[[\"Score\", \"Time\"]]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC() # accepting all the default parameters\n",
    "clf.fit(X, Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which are the bad predictions and find which ones they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = clf.predict(X)\n",
    "len(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(range(len(Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_predictions = []\n",
    "for i in range(len(Y_pred)):\n",
    "    if(Y_pred[i] != Label[i]):\n",
    "        bad_predictions.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92, 288, 298, 358, 413, 560, 747, 761, 781, 809, 819, 853, 880, 921]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bad_predictions)\n",
    "len(bad_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A false positive is when the truth is false but prediction is true "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A false negative is when the truth is true but prediction is false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for false positives and false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_vals = []\n",
    "pred_vals = []\n",
    "for i in range(len(bad_predictions)):\n",
    "    pred_vals.append (Y_pred[bad_predictions[i]])\n",
    "    true_vals.append (Label[bad_predictions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pred_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print(true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {'predictions':pred_vals, \n",
    "     'truth' : true_vals })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a df where we see all mistakes are false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions truth\n",
       "0        False  True\n",
       "1        False  True\n",
       "2        False  True\n",
       "3        False  True\n",
       "4        False  True\n",
       "5        False  True\n",
       "6        False  True\n",
       "7        False  True\n",
       "8        False  True\n",
       "9        False  True\n",
       "10       False  True\n",
       "11       False  True\n",
       "12       False  True\n",
       "13       False  True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF WEEK 3 - \"use scikit learn, SVM to predict helpful scores in Amazon dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START OF WEEK 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. enumerate()\n",
    "### 2. yield\n",
    "### 3. zip\n",
    "### 4. Fuck's up with his for loops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from https://github.com/joelgrus/data-science-from-scratch\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def in_random_order(data):\n",
    "    \"\"\"generator that returns the elements of data in a random order\"\"\"\n",
    "    indexes = [ i for i, in enumerate(data)] #create a list of indexes\n",
    "    random.shuffle(indexes)                  #shuffle them\n",
    "    for i in indexes:                        #return the data in that order\n",
    "        yield data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "def vector_subtract(v, w):\n",
    "    \"\"\"subtracts two vectors componentwise\"\"\"\n",
    "    return [v_i - w_i for v_i, w_i in zip(v,w)]\n",
    "\n",
    "def scalar_multiply(c, v):\n",
    "    return[c * v_i for v_i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#support for target and gradient functions\n",
    "def predict(alpha, beta, x_i):\n",
    "    return beta * x_i + alpha\n",
    "\n",
    "def error(alpha, beta, x_i, y_i):\n",
    "    return y_i - predict(alpha, beta, x_i)\n",
    "\n",
    "#target and gradient functions\n",
    "def squared_error(x_i, y_i, theta):\n",
    "    alpha, beta = theta           #What is this line doing?\n",
    "    return error(alpha, beta, x_i, y_i) ** 2\n",
    "\n",
    "def squared_error_gradient(x_i, y_i, theta):\n",
    "    alpha,beta = theta\n",
    "    return[-2*error(alpha, beta, x_i, y_i),       #partial derivative w.r.t alpha\n",
    "           -2*error(alpha, beta, x_i, y_i) * x_i] # partial derivative w.r.t beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimize_stochastic(taget_fn, gradient_fn, x, y, theta_0, alpha_0 = 0.01):\n",
    "    data = list(zip(x,y))\n",
    "    theta = theta_0                           #initial guess\n",
    "    alpha = alpha_0                           #initial step size\n",
    "    min_theta, min_value = None, float(\"inf\") #the minimum so far\n",
    "    \n",
    "    #if we ever go 1000 iterations with no improvement, stop\n",
    "    while iterations_with_no_improvement < 100:\n",
    "        value = sum(target_fn(x_i, y_i, theta) for x_i, y_i in data)\n",
    "        \n",
    "        if value < min_value:\n",
    "            #if we've found a new minimum remember it\n",
    "            #and go back to the original step size\n",
    "            min_theta, min_value = theta, value\n",
    "            iterations_with_no_improvement = 0\n",
    "            alpha = alpha_0\n",
    "        else:\n",
    "            #otherwise we are not improving so shrink the step size\n",
    "            iterations_with_no_improvement = iterations_with_no_improvement + 1\n",
    "            alpha = alpha * 0.9\n",
    "            \n",
    "        #and take a gradient step for each of the data points\n",
    "        for x_i, y_i in in_random_order(data):\n",
    "            gradient_i = gradient_fn(x_i, y_i, theta)\n",
    "            theta = vector_subtract(theta, scalar_multiply(alpha, gradient_i))\n",
    "            \n",
    "        return min_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data\n",
    "x = np.array([1,2,4,3,5])\n",
    "y = np.array([1,3,3,2,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First try to calculate the slope and intercept using the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xbar = np.average(x)\n",
    "Ybar = np.average(y)\n",
    "X_minus_Xbar = np.subtract(x, [Xbar])\n",
    "Y_minus_Ybar = np.subtract(y, [Ybar])\n",
    "X_minus_Xbar_squared = np.power(X_minus_Xbar, 2)\n",
    "sum_X_minus_Xbar_times_Y_minus_Ybar = np.vdot(X_minus_Xbar, Y_minus_Ybar)\n",
    "sum_X_minus_Xbar_squared = np.sum(X_minus_Xbar_squared)\n",
    "b = sum_X_minus_Xbar_times_Y_minus_Ybar / sum_X_minus_Xbar_squared                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Ybar - (b*Xbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept is 0.4 \n",
      "\n",
      "The slope is 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"The intercept is\", a, \"\\n\")\n",
    "print(\"The slope is\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
