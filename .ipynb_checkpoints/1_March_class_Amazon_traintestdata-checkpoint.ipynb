{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports and specifications\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#To validate/cross validate--create training and test data\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call data\n",
    "amazon = pd.read_csv('Amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create 4 object for labels and features of TRAIN and TEST\n",
    "\n",
    "raw_data_train, raw_data_test, y_train, y_test = train_test_split(amazon, amazon['helpful'],\n",
    "                                                                 test_size=0.2, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 13)\n",
      "(91000, 13)\n",
      "(364000,)\n",
      "(91000,)\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_train.shape)\n",
    "print(raw_data_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_train.to_csv('raw_data_train.csv')\n",
    "raw_data_test.to_csv('raw_data_test.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "y_test.to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6 notebook Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryClassificationPerformance():\n",
    "    '''Performance measures to evaluate the fit of a binary classification model'''\n",
    "    \n",
    "    def __init__(self, predictions, labels, desc, probabilities=None):\n",
    "        '''Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y'''\n",
    "        '''probabilities-optional, probability that Y is equal to True'''\n",
    "        self.probabilities = probabilities\n",
    "        self.performance_df = pd.concat([pd.DataFrame(predictions), pd.DataFrame(labels)], axis=1)\n",
    "        self.performance_df.columns = ['preds', 'labls']\n",
    "        self.desc = desc\n",
    "        self.performance_measures = {}\n",
    "  \n",
    "    def compute_measures(self):\n",
    "        '''Compute performance measures defined by Flach p. 57'''\n",
    "        self.performance_measures['Pos'] = self.performance_df['preds'].sum()\n",
    "        self.performance_measures['Neg'] = self.performance_df.shape[0] - self.performance_df['preds'].sum()\n",
    "        self.performance_measures['TP'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == True)).sum()\n",
    "        self.performance_measures['TN'] = ((self.performance_df['preds'] == False) & (self.performance_df['labls'] == False)).sum()\n",
    "        self.performance_measures['FP'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == False)).sum()\n",
    "        self.performance_measures['FN'] = ((self.performance_df['preds'] == False) & (self.performance_df['labls'] == True)).sum()\n",
    "        self.performance_measures['Accuracy'] = (self.performance_measures['TP'] + self.performance_measures['TN']) / (self.performance_measures['Pos'] + self.performance_measures['Neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('raw_data_train.csv')\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      188941         73792   73793  B000HDOPZG   AWIW6ZQ47MNJH   \n",
      "1      220592        200455  200456  B008O2EHNC  A21S0K5PU4YO9L   \n",
      "2       20265        529969  529970  B000O2APH2  A3621NVN1FSGMO   \n",
      "3      265113        197131  197132  B000FNH1C2  A2SHXT0YBG49TO   \n",
      "4       14678         57724   57725  B000EVOSE4  A1JFIH71386GBV   \n",
      "\n",
      "                          ProfileName  HelpfulnessNumerator  \\\n",
      "0                          S F Norman                     1   \n",
      "1                      third time mom                    17   \n",
      "2  Norman J. Pieniazek \"Orchid lover\"                     1   \n",
      "3                            K. Lantz                     1   \n",
      "4             Jennifer Anderson \"Jen\"                     0   \n",
      "\n",
      "   HelpfulnessDenominator  Score        Time  \\\n",
      "0                       1      5  1333929600   \n",
      "1                      17      5  1338854400   \n",
      "2                       1      5  1245888000   \n",
      "3                       1      5  1202515200   \n",
      "4                       0      5  1232323200   \n",
      "\n",
      "                                       Summary  \\\n",
      "0                                 Outstanding!   \n",
      "1  fine substitute for the hard to find Senseo   \n",
      "2                          Grain-free cat food   \n",
      "3                                great cookies   \n",
      "4                                  Yummy Gummi   \n",
      "\n",
      "                                                Text  helpScore helpful  \n",
      "0  I first tried these cookies while visiting fam...        1.0   False  \n",
      "1  The Senseo pods are, at the time of this writi...        1.0    True  \n",
      "2  My eight year old cat is indoor/outdoor and li...        1.0   False  \n",
      "3  i love these cookies. i can eat wheat and glut...        1.0   False  \n",
      "4  Present for my brother, I bought two bags, 10l...        NaN   False  \n",
      "0.0731318681319\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 131072)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "X_hv = hv.fit_transform(amazon.Text)\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hv.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "joblib.dump(hv, 'hv.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.pkl', 'transformer.pkl_01.npy', 'transformer.pkl_02.npy']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n",
    "joblib.dump(transformer, 'transformer.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  reviewLen\n",
      "0      5        519\n",
      "1      5       1395\n",
      "2      5        821\n",
      "3      5         82\n",
      "4      5        169\n",
      "5      5        159\n",
      "6      4        297\n",
      "7      2        628\n",
      "8      1        607\n",
      "9      3       3188\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\"]]\n",
    "print(X_quant_features.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try person who wrote it\n",
    "### try sentiment analysis"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
